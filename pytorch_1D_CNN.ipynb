{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt9BE42e0kXhKVGcfb+hdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenxiaHu/DeepLearning/blob/main/pytorch_1D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dJBlpMEuYtuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "\n",
        "Dependencies:\n",
        "* torch: 0.1.11\n",
        "* matplotlib"
      ],
      "metadata": {
        "id": "xt7e8o5FYwDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step0: import python packages"
      ],
      "metadata": {
        "id": "ZiTV7aUDZq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as Fun\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import requests\n",
        "torch.manual_seed(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJn2LrnY_Oz",
        "outputId": "4c5cdc7f-7263-4196-a0c5-579951447aaf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb1d8181110>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step1: import data"
      ],
      "metadata": {
        "id": "7bEJ9iCYZxe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqid=\"https://raw.githubusercontent.com/BenxiaHu/DeepLearning/main/sequences.txt\"\n",
        "labelid=\"https://raw.githubusercontent.com/BenxiaHu/DeepLearning/main/labels.txt\"\n",
        "input = pd.read_csv(seqid,header=None)\n",
        "label = pd.read_table(labelid,header=None)\n",
        "\n",
        "\n",
        "# Convert input to one-hot code\n",
        "#def one_hot_encoding(seq):\n",
        "#    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
        "#    one_hot = [mapping[nuc] for nuc in seq]\n",
        "#    return np.array(one_hot)\n",
        "\n",
        "#one_hot_input = np.array([one_hot_encoding(seq) for seq in input[0]])\n",
        "#\n",
        "#one_hot_input = torch.from_numpy(one_hot_input)\n",
        "#one_hot_input = one_hot_input.permute(0, 2, 1)\n",
        "#print(one_hot_input.shape)\n",
        "\n",
        "# Split the data into training, test, and prediction sets\n",
        "# Split the data into training, testing, and prediction sets\n",
        "#x_train, x_test, y_train, y_test = train_test_split(one_hot_input, label, test_size=0.3, random_state=42)\n",
        "#x_test, x_pred, y_test, y_pred = train_test_split(x_test, y_test, test_size=0.67, random_state=42)\n",
        "#print(x_train.shape)\n",
        "#print(x_test.shape)\n",
        "\n",
        "\n",
        "DNA = np.zeros(shape=(len(input),len(input[0][0]),4))\n",
        "labelid = np.zeros(shape=(len(input),))\n",
        "#print(DNA.shape)\n",
        "#print(labelid.shape)\n",
        "\n",
        "for i in range(input.shape[0]):\n",
        "    seq_array = array(list(input[0][i]))\n",
        "    #integer encode the sequence\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
        "    #one hot the sequence\n",
        "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "    #reshape because that's what OneHotEncoder likes\n",
        "    #print(integer_encoded_seq.shape)\n",
        "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
        "    #print(integer_encoded_seq.shape)\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
        "    #print(onehot_encoded_seq.shape)\n",
        "    #print(len(onehot_encoded_seq))\n",
        "    DNA[i] = onehot_encoded_seq\n",
        "    #DNA[i] = onehot_encoded_seq.reshape(4,len(onehot_encoded_seq))\n",
        "    labelid[i] = label[0][i]\n",
        "\n",
        "#print(DNA.shape)\n",
        "#print(labelid.shape)\n",
        "\n",
        "DNA = torch.tensor(DNA)\n",
        "DNA = DNA.permute(0, 2, 1)\n",
        "labelid =  torch.tensor(labelid)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    DNA = DNA.to(\"cuda:0\")\n",
        "    labelid =  labelid.to(\"cuda:0\")\n",
        "#print(DNA.is_cuda)\n",
        "\n",
        "#print(np.shape(DNA))\n",
        "#embed_x = embed_x.permute(0, 2, 1)"
      ],
      "metadata": {
        "id": "hcsO9VnIZ5Sa"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step2: split the data into training, test and prediction data"
      ],
      "metadata": {
        "id": "mda3oRSQiziW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input_tensor = DNA\n",
        "#label_tensor = labelid\n",
        "# pick 1400 samples as training data\n",
        "#print(input_tensor[0:1400,:,:].shape)\n",
        "#print(label_tensor[0:1400].shape)\n",
        "\n",
        "# Split the data into training, test, and prediction sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(DNA, labelid, test_size=0.3, random_state=42)\n",
        "\n",
        "#print(x_train.shape)\n",
        "# Hyper Parameters\n",
        "EPOCH = 10000              # train the training data n times, to save time, we just train 1 epoch\n",
        "BATCH_SIZE = 100\n",
        "LR = 0.01                 # learning rate\n",
        "torch_dataset = Data.TensorDataset(x_train, y_train)\n",
        "train_loader = Data.DataLoader(dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "torch_dataset2 = Data.TensorDataset(x_test, y_test)\n",
        "test_loader = Data.DataLoader(dataset=torch_dataset2, shuffle=True)\n",
        "              \n",
        "# Data Loader for easy mini-batch return in training, the image batch shape will be (100, 1, 50, 4)\n",
        "\n",
        "#for i, j in enumerate(train_loader):\n",
        "    #x, y = j\n",
        "    #print('batch:{0} x:{1}  y: {2}'.format(i, x, y))\n",
        "    #print(i)\n",
        "    #print(x.shape)\n",
        "    #print(y.shape)\n",
        "\n",
        "# pick 400 samples as prediction data\n",
        "#test_x2 = Variable(input_tensor[1600:2000,:,:]).type(torch.FloatTensor)\n",
        "#test_y2 = label_tensor[1600:2000]\n"
      ],
      "metadata": {
        "id": "lIn4WnALi6Bc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step4: build the 1D-CNN model"
      ],
      "metadata": {
        "id": "2ipkZI_vvddy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         # input shape (50,4,50)\n",
        "            nn.Conv1d(\n",
        "                in_channels=4,              # input height\n",
        "                out_channels=32,            # n_filters\n",
        "                kernel_size=11,             # filter size\n",
        "                stride=1,                   # filter movement/step\n",
        "                padding=0                   # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
        "            ),                              # output shape (32, 1, 40)\n",
        "            nn.ReLU(),                      # activation\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0)                  # choose max value in 1x2 area, output shape (32, 1, 38)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         # input shape (16, 1, 38)\n",
        "            nn.Conv1d(\n",
        "                in_channels=32,             # input height\n",
        "                out_channels=16,            # n_filters\n",
        "                kernel_size=11,             # filter size\n",
        "                stride=1,                   # filter movement/step\n",
        "                padding=0                   # output shape (16, 1, 28)\n",
        "            ),\n",
        "            nn.ReLU(),                      # activation\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0)                # output shape (16, 1, 26)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(       # input shape (16, 1, 26)\n",
        "            nn.Conv1d(\n",
        "                in_channels=16,           # input height\n",
        "                out_channels=8,           # n_filters\n",
        "                kernel_size=11,           # filter size\n",
        "                stride=1,                 # filter movement/step\n",
        "                padding=0                 # output shape (8, 1, 16)\n",
        "            ),\n",
        "            nn.ReLU(),                    # activation\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0)                # output shape (8, 1, 14)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(       # input shape (8, 1, 14)\n",
        "            nn.Conv1d(\n",
        "                in_channels=8,            # input height\n",
        "                out_channels=4,           # n_filters\n",
        "                kernel_size=11,           # filter size\n",
        "                stride=1,                 # filter movement/step\n",
        "                padding=0                 # output shape (4, 1, 6)\n",
        "            ),\n",
        "            nn.ReLU(),                    # activation\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=0)                # output shape (4, 1, 2)\n",
        "        )\n",
        "        #self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(112, 10)     # fully connected layer\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(10, 2)       # fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        #print(x.size())            # torch.Size([50, 32, 38])\n",
        "        x = self.conv2(x)\n",
        "        #print(x.size())            # torch.Size([50, 16, 26])\n",
        "        x = self.conv3(x)\n",
        "        #print(x.size())            # torch.Size([50, 8, 14])\n",
        "        #x = self.conv4(x)\n",
        "        #print(x.size())            # torch.Size([50, 4, 2])\n",
        "        x = x.view(x.size(0), -1)   # flatten the output to 2 dimensions from 3 dimensions\n",
        "        #print(x.size())            # torch.Size([50, 112])\n",
        "        x = self.fc1(x)\n",
        "        #print(x.size())            # torch.Size([50, 10])\n",
        "        x = self.relu(x)\n",
        "        #print(x.size())            # torch.Size([50, 10])\n",
        "        x = self.dropout(x) \n",
        "        #print(x.size())            # torch.Size([50, 10])\n",
        "        x = x.view(x.size(0), -1)   # flatten the output 1 dimension from 2 dimensions\n",
        "        out = self.fc2(x)\n",
        "        return out, x               # return x for visualization\n",
        "\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)  # net architecture\n",
        "\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
        "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clAfv5DQvc5c",
        "outputId": "98ff5b09-6335-4ddc-c8f1-149c67d22b81"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv1d(4, 32, kernel_size=(11,), stride=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv1d(32, 16, kernel_size=(11,), stride=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv1d(16, 8, kernel_size=(11,), stride=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv1d(8, 4, kernel_size=(11,), stride=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=112, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# running the CNN model"
      ],
      "metadata": {
        "id": "avagtSaveVqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing\n",
        "optimizer.zero_grad()           # clear gradients for this training step\n",
        "for epoch in range(EPOCH):\n",
        "    running_loss = 0.0\n",
        "    for i, (b_x, b_y) in enumerate(train_loader):  # gives batch data, normalize x when iterate train_loader\n",
        "        #print(b_x)\n",
        "        b_x = Variable(b_x).type(torch.FloatTensor)\n",
        "        b_y = b_y.type(torch.LongTensor)\n",
        "        optimizer.zero_grad()           # clear gradients for this training step\n",
        "        output = cnn(b_x)[0]            # cnn output\n",
        "        loss = loss_func(output, b_y)   # cross entropy loss\n",
        "        loss.backward()                 # backpropagation, compute gradients\n",
        "        optimizer.step()                # apply gradients\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 0:    # print every 100 mini-batches\n",
        "            #print(i)\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')\n",
        "\n",
        "# Letâ€™s quickly save our trained model:\n",
        "\n",
        "!pwd\n",
        "torch.save(cnn.state_dict(), \"./content\")\n"
      ],
      "metadata": {
        "id": "Zckte_qdea_1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# apply the model to the test data"
      ],
      "metadata": {
        "id": "UVSipUZwos-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CNN()\n",
        "net.load_state_dict(torch.load(\"./content\"))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for i, (b_x, b_y) in enumerate(test_loader):\n",
        "        b_x = Variable(b_x).type(torch.FloatTensor)\n",
        "        #print(b_x.shape)\n",
        "        #b_y = b_y.type(torch.LongTensor)\n",
        "        # calculate outputs by running the network\n",
        "        outputs = net(b_x)\n",
        "        #print(outputs[0].shape)\n",
        "        #print(outputs[1].shape)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs[0], 1)\n",
        "        total += b_y.size(0)\n",
        "        correct += (predicted == b_y).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjjcoqJLoqDC",
        "outputId": "559b1591-3691-4f7d-e4ae-f2e720729ff8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 99 %\n"
          ]
        }
      ]
    }
  ]
}