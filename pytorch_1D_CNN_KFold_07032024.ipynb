{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenxiaHu/DeepLearning/blob/main/pytorch_1D_CNN_KFold_07032024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJBlpMEuYtuf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt7e8o5FYwDV"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "\n",
        "Dependencies:\n",
        "* torch: 0.1.11\n",
        "* matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiTV7aUDZq2F"
      },
      "source": [
        "# step0: import python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BCJn2LrnY_Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08aff016-605e-4358-b505-2153fc4b9052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c0b642c0410>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as Fun\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import requests\n",
        "from torch.nn import LogSoftmax\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bEJ9iCYZxe6"
      },
      "source": [
        "# step1: import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcsO9VnIZ5Sa",
        "outputId": "ef9dd10e-b7f1-481e-94de-d808ec5fd309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        chr      start        end  silencer                     peakid\n",
            "0      chr1  113408175  113408375         1   chr1:113408175-113408375\n",
            "1     chr10    6107715    6107915         1      chr10:6107715-6107915\n",
            "2     chr10   15538675   15538875         1    chr10:15538675-15538875\n",
            "3     chr11  114339756  114339956         1  chr11:114339756-114339956\n",
            "4     chr17   41121376   41121576         1    chr17:41121376-41121576\n",
            "...     ...        ...        ...       ...                        ...\n",
            "7227   chrX   93929096   93929296         0     chrX:93929096-93929296\n",
            "7228   chrX  101946395  101946595         0   chrX:101946395-101946595\n",
            "7229   chrX  130859105  130859305         0   chrX:130859105-130859305\n",
            "7230   chrX  131424075  131424275         0   chrX:131424075-131424275\n",
            "7231   chrX  141256436  141256636         0   chrX:141256436-141256636\n",
            "\n",
            "[7232 rows x 5 columns]\n",
            "(2000, 1)\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "seqid=\"https://raw.githubusercontent.com/BenxiaHu/DeepLearning/main/K562_MPRA_Silencers.txt\"\n",
        "#print(seqid)\n",
        "seqid = pd.read_csv(seqid,header=0,sep=\"\\t\")\n",
        "seqid[\"peakid\"] = seqid['chr'] +\":\"+ seqid[\"start\"].astype(str) +\"-\"+ seqid[\"end\"].astype(str)\n",
        "print(seqid)\n",
        "seqid = seqid[[\"peakid\",\"silencer\"]]\n",
        "#print(seqid)\n",
        "\n",
        "fastaid=\"https://raw.githubusercontent.com/BenxiaHu/DeepLearning/main/K562_MPRA_Silencers.fasta\"\n",
        "fastaid = pd.read_table(fastaid,header=None,sep=\"\\t\")\n",
        "#print(fastaid)\n",
        "fastaid.rename(columns={0:\"peakid\",1:\"fasta\"},inplace=True)\n",
        "\n",
        "result = pd.merge(fastaid, seqid, how='inner', on=['peakid', 'peakid'])\n",
        "\n",
        "result[[\"fasta\"]] = result[[\"fasta\"]].apply(lambda x: x.astype(str).str.upper())\n",
        "\n",
        "result = result[[\"fasta\",\"silencer\"]]\n",
        "\n",
        "#label=\"https://raw.githubusercontent.com/BenxiaHu/DeepLearning/main/labels.txt\"\n",
        "#label = pd.read_table(labelid,header=None)\n",
        "input = result[[\"fasta\"]]\n",
        "print(input.shape)\n",
        "label = result[[\"silencer\"]]\n",
        "\n",
        "\n",
        "DNA = np.zeros(shape=(len(input),len(input[\"fasta\"][0]),4))\n",
        "labelid = np.zeros(shape=(len(input),))\n",
        "#print(DNA.shape)\n",
        "#print(labelid.shape)\n",
        "\n",
        "for i in range(input.shape[0]):\n",
        "    seq_array = array(list(input[\"fasta\"][i]))\n",
        "    #integer encode the sequence\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
        "    #one hot the sequence\n",
        "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "    #reshape because that's what OneHotEncoder likes\n",
        "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
        "    DNA[i] = onehot_encoded_seq\n",
        "    #DNA[i] = onehot_encoded_seq.reshape(4,len(onehot_encoded_seq))\n",
        "    labelid[i] = label[\"silencer\"][i]\n",
        "\n",
        "DNA = torch.tensor(DNA)\n",
        "DNA = DNA.permute(0, 2, 1)\n",
        "labelid =  torch.tensor(labelid)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    DNA = DNA.to(\"cuda:0\")\n",
        "    labelid =  labelid.to(\"cuda:0\")\n",
        "print(DNA.is_cuda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ipkZI_vvddy"
      },
      "source": [
        "# step2: build the 1D-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "clAfv5DQvc5c"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, sequence_length=200, n_genomic_features=2):\n",
        "        super(CNN, self).__init__()\n",
        "        conv_kernel_size = 4\n",
        "        pool_kernel_size = 2\n",
        "        self.conv_net = nn.Sequential(\n",
        "            #nn.Dropout(p=0.2),\n",
        "            nn.Conv1d(in_channels=4, out_channels=128, kernel_size=conv_kernel_size, padding=0),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(in_channels=128, out_channels=64, kernel_size=conv_kernel_size, padding=0),\n",
        "            nn.BatchNorm1d(num_features=64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(in_channels=64, out_channels=32, kernel_size=conv_kernel_size, padding=0),\n",
        "            nn.BatchNorm1d(num_features=32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=conv_kernel_size, padding=0),\n",
        "            nn.BatchNorm1d(num_features=16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.4))\n",
        "\n",
        "        reduce_by = conv_kernel_size - 1\n",
        "        pool_kernel_size = float(pool_kernel_size)\n",
        "\n",
        "        self.n_channels = int(\n",
        "                np.floor(\n",
        "                    (np.floor(\n",
        "                        (np.floor(\n",
        "                            (np.floor(\n",
        "                             (sequence_length - reduce_by) / pool_kernel_size)\n",
        "                            - reduce_by) / pool_kernel_size)\n",
        "                            - reduce_by) / pool_kernel_size)\n",
        "                            - reduce_by) / pool_kernel_size))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16 * self.n_channels, n_genomic_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_genomic_features, n_genomic_features),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward propagation of a batch.\n",
        "        \"\"\"\n",
        "        out = self.conv_net(x)\n",
        "        reshape_out = out.view(out.size(0), 16 * self.n_channels)\n",
        "        predict = self.classifier(reshape_out)\n",
        "        return predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avagtSaveVqP"
      },
      "source": [
        "# step3 running the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zckte_qdea_1",
        "outputId": "b08e1722-fdf8-411e-ccd0-5f80faa160fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the loss on each epoch: 0, loss: 0.7212875932455063\n",
            "the test accuracy on each epoch: 0, test accuracy: 49\n",
            "the validation accuracy on each epoch: 0, validation accuracy: 53\n",
            "the loss on each epoch: 10, loss: 0.6477638483047485\n",
            "the test accuracy on each epoch: 10, test accuracy: 49\n",
            "the validation accuracy on each epoch: 10, validation accuracy: 54\n",
            "the loss on each epoch: 20, loss: 0.6150897443294525\n",
            "the test accuracy on each epoch: 20, test accuracy: 50\n",
            "the validation accuracy on each epoch: 20, validation accuracy: 52\n",
            "the loss on each epoch: 30, loss: 0.572259464434215\n",
            "the test accuracy on each epoch: 30, test accuracy: 51\n",
            "the validation accuracy on each epoch: 30, validation accuracy: 53\n",
            "the loss on each epoch: 40, loss: 0.5560174786618778\n",
            "the test accuracy on each epoch: 40, test accuracy: 52\n",
            "the validation accuracy on each epoch: 40, validation accuracy: 53\n",
            "the loss on each epoch: 50, loss: 0.522740435387407\n",
            "the test accuracy on each epoch: 50, test accuracy: 54\n",
            "the validation accuracy on each epoch: 50, validation accuracy: 56\n",
            "the loss on each epoch: 60, loss: 0.5075575177158628\n",
            "the test accuracy on each epoch: 60, test accuracy: 55\n",
            "the validation accuracy on each epoch: 60, validation accuracy: 60\n",
            "the loss on each epoch: 70, loss: 0.4824687657611711\n",
            "the test accuracy on each epoch: 70, test accuracy: 57\n",
            "the validation accuracy on each epoch: 70, validation accuracy: 62\n",
            "the loss on each epoch: 80, loss: 0.44181033968925476\n",
            "the test accuracy on each epoch: 80, test accuracy: 58\n",
            "the validation accuracy on each epoch: 80, validation accuracy: 65\n",
            "the loss on each epoch: 90, loss: 0.43054305016994476\n",
            "the test accuracy on each epoch: 90, test accuracy: 57\n",
            "the validation accuracy on each epoch: 90, validation accuracy: 65\n",
            "the loss on each epoch: 100, loss: 0.3981602340936661\n",
            "the test accuracy on each epoch: 100, test accuracy: 57\n",
            "the validation accuracy on each epoch: 100, validation accuracy: 66\n",
            "the loss on each epoch: 110, loss: 0.39823224395513535\n",
            "the test accuracy on each epoch: 110, test accuracy: 60\n",
            "the validation accuracy on each epoch: 110, validation accuracy: 61\n",
            "the loss on each epoch: 120, loss: 0.3636946273701532\n",
            "the test accuracy on each epoch: 120, test accuracy: 60\n",
            "the validation accuracy on each epoch: 120, validation accuracy: 67\n",
            "the loss on each epoch: 130, loss: 0.33035459156547275\n",
            "the test accuracy on each epoch: 130, test accuracy: 62\n",
            "the validation accuracy on each epoch: 130, validation accuracy: 72\n",
            "the loss on each epoch: 140, loss: 0.33264016253607614\n",
            "the test accuracy on each epoch: 140, test accuracy: 60\n",
            "the validation accuracy on each epoch: 140, validation accuracy: 66\n",
            "the loss on each epoch: 150, loss: 0.31102040889007704\n",
            "the test accuracy on each epoch: 150, test accuracy: 62\n",
            "the validation accuracy on each epoch: 150, validation accuracy: 61\n",
            "the loss on each epoch: 160, loss: 0.2841749611709799\n",
            "the test accuracy on each epoch: 160, test accuracy: 63\n",
            "the validation accuracy on each epoch: 160, validation accuracy: 72\n",
            "the loss on each epoch: 170, loss: 0.30002996272274424\n",
            "the test accuracy on each epoch: 170, test accuracy: 65\n",
            "the validation accuracy on each epoch: 170, validation accuracy: 71\n",
            "the loss on each epoch: 180, loss: 0.2792948234294142\n",
            "the test accuracy on each epoch: 180, test accuracy: 64\n",
            "the validation accuracy on each epoch: 180, validation accuracy: 69\n",
            "the loss on each epoch: 190, loss: 0.24721557859863555\n",
            "the test accuracy on each epoch: 190, test accuracy: 65\n",
            "the validation accuracy on each epoch: 190, validation accuracy: 72\n",
            "the loss on each epoch: 200, loss: 0.2444897528205599\n",
            "the test accuracy on each epoch: 200, test accuracy: 67\n",
            "the validation accuracy on each epoch: 200, validation accuracy: 69\n",
            "the loss on each epoch: 210, loss: 0.2428948932460376\n",
            "the test accuracy on each epoch: 210, test accuracy: 68\n",
            "the validation accuracy on each epoch: 210, validation accuracy: 73\n",
            "the loss on each epoch: 220, loss: 0.2195327633193561\n",
            "the test accuracy on each epoch: 220, test accuracy: 69\n",
            "the validation accuracy on each epoch: 220, validation accuracy: 71\n",
            "the loss on each epoch: 230, loss: 0.2008263325052602\n",
            "the test accuracy on each epoch: 230, test accuracy: 70\n",
            "the validation accuracy on each epoch: 230, validation accuracy: 72\n",
            "the loss on each epoch: 240, loss: 0.20137464148657663\n",
            "the test accuracy on each epoch: 240, test accuracy: 69\n",
            "the validation accuracy on each epoch: 240, validation accuracy: 70\n",
            "the loss on each epoch: 250, loss: 0.20149078353175096\n",
            "the test accuracy on each epoch: 250, test accuracy: 68\n",
            "the validation accuracy on each epoch: 250, validation accuracy: 71\n",
            "the loss on each epoch: 260, loss: 0.19064254127442837\n",
            "the test accuracy on each epoch: 260, test accuracy: 70\n",
            "the validation accuracy on each epoch: 260, validation accuracy: 68\n",
            "the loss on each epoch: 270, loss: 0.18371850119105407\n",
            "the test accuracy on each epoch: 270, test accuracy: 69\n",
            "the validation accuracy on each epoch: 270, validation accuracy: 73\n",
            "the loss on each epoch: 280, loss: 0.1700770580875022\n",
            "the test accuracy on each epoch: 280, test accuracy: 71\n",
            "the validation accuracy on each epoch: 280, validation accuracy: 74\n",
            "the loss on each epoch: 290, loss: 0.17084548635674374\n",
            "the test accuracy on each epoch: 290, test accuracy: 71\n",
            "the validation accuracy on each epoch: 290, validation accuracy: 70\n",
            "the loss on each epoch: 300, loss: 0.17169977272195475\n",
            "the test accuracy on each epoch: 300, test accuracy: 73\n",
            "the validation accuracy on each epoch: 300, validation accuracy: 73\n",
            "the loss on each epoch: 310, loss: 0.16015818369175708\n",
            "the test accuracy on each epoch: 310, test accuracy: 73\n",
            "the validation accuracy on each epoch: 310, validation accuracy: 73\n",
            "the loss on each epoch: 320, loss: 0.14842072581606253\n",
            "the test accuracy on each epoch: 320, test accuracy: 71\n",
            "the validation accuracy on each epoch: 320, validation accuracy: 73\n",
            "the loss on each epoch: 330, loss: 0.15713124802070005\n",
            "the test accuracy on each epoch: 330, test accuracy: 71\n",
            "the validation accuracy on each epoch: 330, validation accuracy: 69\n",
            "the loss on each epoch: 340, loss: 0.1355367475854499\n",
            "the test accuracy on each epoch: 340, test accuracy: 73\n",
            "the validation accuracy on each epoch: 340, validation accuracy: 73\n",
            "the loss on each epoch: 350, loss: 0.13298702625823872\n",
            "the test accuracy on each epoch: 350, test accuracy: 73\n",
            "the validation accuracy on each epoch: 350, validation accuracy: 71\n",
            "the loss on each epoch: 360, loss: 0.13523543506328548\n",
            "the test accuracy on each epoch: 360, test accuracy: 73\n",
            "the validation accuracy on each epoch: 360, validation accuracy: 72\n",
            "the loss on each epoch: 370, loss: 0.13180915898244297\n",
            "the test accuracy on each epoch: 370, test accuracy: 75\n",
            "the validation accuracy on each epoch: 370, validation accuracy: 73\n",
            "the loss on each epoch: 380, loss: 0.12398926235203232\n",
            "the test accuracy on each epoch: 380, test accuracy: 75\n",
            "the validation accuracy on each epoch: 380, validation accuracy: 73\n",
            "the loss on each epoch: 390, loss: 0.12666256353259087\n",
            "the test accuracy on each epoch: 390, test accuracy: 76\n",
            "the validation accuracy on each epoch: 390, validation accuracy: 72\n",
            "the loss on each epoch: 400, loss: 0.13214700442871877\n",
            "the test accuracy on each epoch: 400, test accuracy: 74\n",
            "the validation accuracy on each epoch: 400, validation accuracy: 72\n",
            "the loss on each epoch: 410, loss: 0.10846669080534152\n",
            "the test accuracy on each epoch: 410, test accuracy: 76\n",
            "the validation accuracy on each epoch: 410, validation accuracy: 71\n",
            "the loss on each epoch: 420, loss: 0.11139122503144401\n",
            "the test accuracy on each epoch: 420, test accuracy: 77\n",
            "the validation accuracy on each epoch: 420, validation accuracy: 71\n",
            "the loss on each epoch: 430, loss: 0.09744710741298539\n",
            "the test accuracy on each epoch: 430, test accuracy: 78\n",
            "the validation accuracy on each epoch: 430, validation accuracy: 75\n",
            "the loss on each epoch: 440, loss: 0.11980677821806499\n",
            "the test accuracy on each epoch: 440, test accuracy: 78\n",
            "the validation accuracy on each epoch: 440, validation accuracy: 73\n",
            "the loss on each epoch: 450, loss: 0.10868592799774238\n",
            "the test accuracy on each epoch: 450, test accuracy: 77\n",
            "the validation accuracy on each epoch: 450, validation accuracy: 72\n",
            "the loss on each epoch: 460, loss: 0.10357318233166422\n",
            "the test accuracy on each epoch: 460, test accuracy: 77\n",
            "the validation accuracy on each epoch: 460, validation accuracy: 71\n",
            "the loss on each epoch: 470, loss: 0.08957767100738627\n",
            "the test accuracy on each epoch: 470, test accuracy: 77\n",
            "the validation accuracy on each epoch: 470, validation accuracy: 71\n",
            "the loss on each epoch: 480, loss: 0.1103168401334967\n",
            "the test accuracy on each epoch: 480, test accuracy: 77\n",
            "the validation accuracy on each epoch: 480, validation accuracy: 73\n",
            "the loss on each epoch: 490, loss: 0.07403726277074643\n",
            "the test accuracy on each epoch: 490, test accuracy: 79\n",
            "the validation accuracy on each epoch: 490, validation accuracy: 75\n",
            "the loss on each epoch: 500, loss: 0.09372560021334461\n",
            "the test accuracy on each epoch: 500, test accuracy: 77\n",
            "the validation accuracy on each epoch: 500, validation accuracy: 70\n",
            "the loss on each epoch: 510, loss: 0.09841151101448174\n",
            "the test accuracy on each epoch: 510, test accuracy: 79\n",
            "the validation accuracy on each epoch: 510, validation accuracy: 73\n",
            "the loss on each epoch: 520, loss: 0.0966784366007362\n",
            "the test accuracy on each epoch: 520, test accuracy: 79\n",
            "the validation accuracy on each epoch: 520, validation accuracy: 72\n",
            "the loss on each epoch: 530, loss: 0.09543131251952477\n",
            "the test accuracy on each epoch: 530, test accuracy: 79\n",
            "the validation accuracy on each epoch: 530, validation accuracy: 73\n",
            "the loss on each epoch: 540, loss: 0.07429146473961216\n",
            "the test accuracy on each epoch: 540, test accuracy: 79\n",
            "the validation accuracy on each epoch: 540, validation accuracy: 70\n",
            "the loss on each epoch: 550, loss: 0.08499466341787151\n",
            "the test accuracy on each epoch: 550, test accuracy: 80\n",
            "the validation accuracy on each epoch: 550, validation accuracy: 73\n",
            "the loss on each epoch: 560, loss: 0.08373606258205005\n",
            "the test accuracy on each epoch: 560, test accuracy: 80\n",
            "the validation accuracy on each epoch: 560, validation accuracy: 75\n",
            "the loss on each epoch: 570, loss: 0.08006710931658745\n",
            "the test accuracy on each epoch: 570, test accuracy: 80\n",
            "the validation accuracy on each epoch: 570, validation accuracy: 70\n",
            "the loss on each epoch: 580, loss: 0.06875082810542413\n",
            "the test accuracy on each epoch: 580, test accuracy: 81\n",
            "the validation accuracy on each epoch: 580, validation accuracy: 73\n",
            "the loss on each epoch: 590, loss: 0.07261323749220797\n",
            "the test accuracy on each epoch: 590, test accuracy: 82\n",
            "the validation accuracy on each epoch: 590, validation accuracy: 74\n",
            "the loss on each epoch: 600, loss: 0.08451010433158704\n",
            "the test accuracy on each epoch: 600, test accuracy: 80\n",
            "the validation accuracy on each epoch: 600, validation accuracy: 70\n",
            "the loss on each epoch: 610, loss: 0.0911031664748277\n",
            "the test accuracy on each epoch: 610, test accuracy: 81\n",
            "the validation accuracy on each epoch: 610, validation accuracy: 75\n",
            "the loss on each epoch: 620, loss: 0.05397788325457701\n",
            "the test accuracy on each epoch: 620, test accuracy: 82\n",
            "the validation accuracy on each epoch: 620, validation accuracy: 75\n",
            "the loss on each epoch: 630, loss: 0.08400857039461178\n",
            "the test accuracy on each epoch: 630, test accuracy: 80\n",
            "the validation accuracy on each epoch: 630, validation accuracy: 76\n",
            "the loss on each epoch: 640, loss: 0.07463280766803239\n",
            "the test accuracy on each epoch: 640, test accuracy: 82\n",
            "the validation accuracy on each epoch: 640, validation accuracy: 75\n",
            "the loss on each epoch: 650, loss: 0.05779483275754111\n",
            "the test accuracy on each epoch: 650, test accuracy: 82\n",
            "the validation accuracy on each epoch: 650, validation accuracy: 76\n",
            "the loss on each epoch: 660, loss: 0.07016857873116221\n",
            "the test accuracy on each epoch: 660, test accuracy: 83\n",
            "the validation accuracy on each epoch: 660, validation accuracy: 75\n",
            "the loss on each epoch: 670, loss: 0.0701475969648787\n",
            "the test accuracy on each epoch: 670, test accuracy: 82\n",
            "the validation accuracy on each epoch: 670, validation accuracy: 72\n",
            "the loss on each epoch: 680, loss: 0.056592440964387994\n",
            "the test accuracy on each epoch: 680, test accuracy: 83\n",
            "the validation accuracy on each epoch: 680, validation accuracy: 75\n",
            "the loss on each epoch: 690, loss: 0.05101213271596602\n",
            "the test accuracy on each epoch: 690, test accuracy: 84\n",
            "the validation accuracy on each epoch: 690, validation accuracy: 71\n",
            "the loss on each epoch: 700, loss: 0.060446004483050535\n",
            "the test accuracy on each epoch: 700, test accuracy: 84\n",
            "the validation accuracy on each epoch: 700, validation accuracy: 75\n",
            "the loss on each epoch: 710, loss: 0.05596140991630299\n",
            "the test accuracy on each epoch: 710, test accuracy: 82\n",
            "the validation accuracy on each epoch: 710, validation accuracy: 73\n",
            "the loss on each epoch: 720, loss: 0.051730847850974114\n",
            "the test accuracy on each epoch: 720, test accuracy: 83\n",
            "the validation accuracy on each epoch: 720, validation accuracy: 74\n",
            "the loss on each epoch: 730, loss: 0.05061166484041938\n",
            "the test accuracy on each epoch: 730, test accuracy: 84\n",
            "the validation accuracy on each epoch: 730, validation accuracy: 76\n",
            "the loss on each epoch: 740, loss: 0.06446999091921109\n",
            "the test accuracy on each epoch: 740, test accuracy: 82\n",
            "the validation accuracy on each epoch: 740, validation accuracy: 74\n",
            "the loss on each epoch: 750, loss: 0.06412430187421185\n",
            "the test accuracy on each epoch: 750, test accuracy: 85\n",
            "the validation accuracy on each epoch: 750, validation accuracy: 77\n",
            "the loss on each epoch: 760, loss: 0.05921507643402687\n",
            "the test accuracy on each epoch: 760, test accuracy: 84\n",
            "the validation accuracy on each epoch: 760, validation accuracy: 75\n",
            "the loss on each epoch: 770, loss: 0.05104274992897574\n",
            "the test accuracy on each epoch: 770, test accuracy: 83\n",
            "the validation accuracy on each epoch: 770, validation accuracy: 72\n",
            "the loss on each epoch: 780, loss: 0.04661351169592568\n",
            "the test accuracy on each epoch: 780, test accuracy: 85\n",
            "the validation accuracy on each epoch: 780, validation accuracy: 77\n",
            "the loss on each epoch: 790, loss: 0.0705033971795014\n",
            "the test accuracy on each epoch: 790, test accuracy: 82\n",
            "the validation accuracy on each epoch: 790, validation accuracy: 76\n",
            "the loss on each epoch: 800, loss: 0.05485546199737915\n",
            "the test accuracy on each epoch: 800, test accuracy: 83\n",
            "the validation accuracy on each epoch: 800, validation accuracy: 74\n",
            "the loss on each epoch: 810, loss: 0.04598777707932251\n",
            "the test accuracy on each epoch: 810, test accuracy: 83\n",
            "the validation accuracy on each epoch: 810, validation accuracy: 73\n",
            "the loss on each epoch: 820, loss: 0.06489978058795844\n",
            "the test accuracy on each epoch: 820, test accuracy: 82\n",
            "the validation accuracy on each epoch: 820, validation accuracy: 75\n",
            "the loss on each epoch: 830, loss: 0.047711958909141164\n",
            "the test accuracy on each epoch: 830, test accuracy: 85\n",
            "the validation accuracy on each epoch: 830, validation accuracy: 76\n",
            "the loss on each epoch: 840, loss: 0.06688475588868771\n",
            "the test accuracy on each epoch: 840, test accuracy: 84\n",
            "the validation accuracy on each epoch: 840, validation accuracy: 77\n",
            "the loss on each epoch: 850, loss: 0.04363897885195911\n",
            "the test accuracy on each epoch: 850, test accuracy: 85\n",
            "the validation accuracy on each epoch: 850, validation accuracy: 72\n",
            "the loss on each epoch: 860, loss: 0.04536260584635394\n",
            "the test accuracy on each epoch: 860, test accuracy: 85\n",
            "the validation accuracy on each epoch: 860, validation accuracy: 76\n",
            "the loss on each epoch: 870, loss: 0.04810222121886909\n",
            "the test accuracy on each epoch: 870, test accuracy: 86\n",
            "the validation accuracy on each epoch: 870, validation accuracy: 74\n",
            "the loss on each epoch: 880, loss: 0.050340642587148716\n",
            "the test accuracy on each epoch: 880, test accuracy: 86\n",
            "the validation accuracy on each epoch: 880, validation accuracy: 74\n",
            "the loss on each epoch: 890, loss: 0.04079750017262995\n",
            "the test accuracy on each epoch: 890, test accuracy: 86\n",
            "the validation accuracy on each epoch: 890, validation accuracy: 73\n",
            "the loss on each epoch: 900, loss: 0.06448643228837422\n",
            "the test accuracy on each epoch: 900, test accuracy: 87\n",
            "the validation accuracy on each epoch: 900, validation accuracy: 78\n",
            "the loss on each epoch: 910, loss: 0.04419782405186977\n",
            "the test accuracy on each epoch: 910, test accuracy: 87\n",
            "the validation accuracy on each epoch: 910, validation accuracy: 71\n",
            "the loss on each epoch: 920, loss: 0.051808519895920266\n",
            "the test accuracy on each epoch: 920, test accuracy: 87\n",
            "the validation accuracy on each epoch: 920, validation accuracy: 75\n",
            "the loss on each epoch: 930, loss: 0.042930665359433205\n",
            "the test accuracy on each epoch: 930, test accuracy: 86\n",
            "the validation accuracy on each epoch: 930, validation accuracy: 74\n",
            "the loss on each epoch: 940, loss: 0.050426261965185404\n",
            "the test accuracy on each epoch: 940, test accuracy: 85\n",
            "the validation accuracy on each epoch: 940, validation accuracy: 76\n",
            "the loss on each epoch: 950, loss: 0.056797558325342834\n",
            "the test accuracy on each epoch: 950, test accuracy: 85\n",
            "the validation accuracy on each epoch: 950, validation accuracy: 79\n",
            "the loss on each epoch: 960, loss: 0.04221426625736058\n",
            "the test accuracy on each epoch: 960, test accuracy: 86\n",
            "the validation accuracy on each epoch: 960, validation accuracy: 71\n",
            "the loss on each epoch: 970, loss: 0.04939216175781829\n",
            "the test accuracy on each epoch: 970, test accuracy: 87\n",
            "the validation accuracy on each epoch: 970, validation accuracy: 72\n",
            "the loss on each epoch: 980, loss: 0.045750414029628574\n",
            "the test accuracy on each epoch: 980, test accuracy: 87\n",
            "the validation accuracy on each epoch: 980, validation accuracy: 77\n",
            "the loss on each epoch: 990, loss: 0.04164126713294536\n",
            "the test accuracy on each epoch: 990, test accuracy: 87\n",
            "the validation accuracy on each epoch: 990, validation accuracy: 72\n",
            "the loss on each epoch: 1000, loss: 0.03875839873217046\n",
            "the test accuracy on each epoch: 1000, test accuracy: 86\n",
            "the validation accuracy on each epoch: 1000, validation accuracy: 73\n",
            "the loss on each epoch: 1010, loss: 0.050206115801951716\n",
            "the test accuracy on each epoch: 1010, test accuracy: 88\n",
            "the validation accuracy on each epoch: 1010, validation accuracy: 75\n",
            "the loss on each epoch: 1020, loss: 0.04360825616666781\n",
            "the test accuracy on each epoch: 1020, test accuracy: 86\n",
            "the validation accuracy on each epoch: 1020, validation accuracy: 73\n",
            "the loss on each epoch: 1030, loss: 0.045027037882911305\n",
            "the test accuracy on each epoch: 1030, test accuracy: 88\n",
            "the validation accuracy on each epoch: 1030, validation accuracy: 73\n",
            "the loss on each epoch: 1040, loss: 0.04792965388125075\n",
            "the test accuracy on each epoch: 1040, test accuracy: 86\n",
            "the validation accuracy on each epoch: 1040, validation accuracy: 75\n",
            "the loss on each epoch: 1050, loss: 0.03273849129410727\n",
            "the test accuracy on each epoch: 1050, test accuracy: 87\n",
            "the validation accuracy on each epoch: 1050, validation accuracy: 72\n",
            "the loss on each epoch: 1060, loss: 0.047477609918652366\n",
            "the test accuracy on each epoch: 1060, test accuracy: 86\n",
            "the validation accuracy on each epoch: 1060, validation accuracy: 71\n",
            "the loss on each epoch: 1070, loss: 0.04959670409360634\n",
            "the test accuracy on each epoch: 1070, test accuracy: 88\n",
            "the validation accuracy on each epoch: 1070, validation accuracy: 74\n",
            "the loss on each epoch: 1080, loss: 0.044091448869689236\n",
            "the test accuracy on each epoch: 1080, test accuracy: 87\n",
            "the validation accuracy on each epoch: 1080, validation accuracy: 75\n",
            "the loss on each epoch: 1090, loss: 0.04688461502415261\n",
            "the test accuracy on each epoch: 1090, test accuracy: 87\n",
            "the validation accuracy on each epoch: 1090, validation accuracy: 72\n",
            "the loss on each epoch: 1100, loss: 0.040246437108310475\n",
            "the test accuracy on each epoch: 1100, test accuracy: 88\n",
            "the validation accuracy on each epoch: 1100, validation accuracy: 77\n",
            "the loss on each epoch: 1110, loss: 0.04315670230425894\n",
            "the test accuracy on each epoch: 1110, test accuracy: 86\n",
            "the validation accuracy on each epoch: 1110, validation accuracy: 71\n",
            "the loss on each epoch: 1120, loss: 0.03907680350156235\n",
            "the test accuracy on each epoch: 1120, test accuracy: 88\n",
            "the validation accuracy on each epoch: 1120, validation accuracy: 74\n"
          ]
        }
      ],
      "source": [
        "# training and testing\n",
        "cnn = CNN()\n",
        "LR = 0.001\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=LR,momentum=0.9,weight_decay=1e-3)   # optimize all cnn parameters\n",
        "optimizer.zero_grad()           # clear gradients for this training step\n",
        "loss_func = nn.BCELoss()                  # the target label is not one-hotted\n",
        "#print(cnn)  # net architecture\n",
        "EPOCH = 2000              # train the training data n times, to save time, we just train 1 epoch\n",
        "\n",
        "train_losses = {}\n",
        "totalcorrectTest = {}\n",
        "totalcorrect = {}\n",
        "BATCH_SIZE = 64\n",
        "NUM_FOLDS = 10\n",
        "\n",
        "all_labels = {}\n",
        "all_probs = {}\n",
        "\n",
        "skf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=123)\n",
        "\n",
        "for fold, (train_index, test_index)  in enumerate(skf.split(DNA, labelid)):\n",
        "    x_train, x_test = DNA[train_index], DNA[test_index]\n",
        "    y_train, y_test = labelid[train_index], labelid[test_index]\n",
        "    torch_dataset = Data.TensorDataset(x_train, y_train)\n",
        "    train_loader = Data.DataLoader(dataset= torch_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    torch_dataset2 = Data.TensorDataset(x_test, y_test)\n",
        "    test_loader = Data.DataLoader(dataset=torch_dataset2, batch_size=BATCH_SIZE,shuffle=True, drop_last=True)\n",
        "    train_losses[str(fold)] = []\n",
        "    totalcorrect[str(fold)] = []\n",
        "    totalcorrectTest[str(fold)] = []\n",
        "    all_labels[str(fold)] = []\n",
        "    all_probs[str(fold)] = []\n",
        "    for epoch in range(EPOCH):\n",
        "        cnn.train()\n",
        "        running_loss = 0.0\n",
        "        correctTest = 0\n",
        "        totalTest = 0\n",
        "        j = 0\n",
        "        for i, (b_x, b_y) in enumerate(train_loader):  # gives batch data, normalize x when iterate train_loader\n",
        "            b_x = Variable(b_x).type(torch.FloatTensor)\n",
        "            b_y = Variable(b_y).type(torch.LongTensor)\n",
        "            b_y = b_y.type(torch.FloatTensor)\n",
        "            optimizer.zero_grad()           # clear gradients for this training step\n",
        "            output = cnn(b_x)               # cnn output\n",
        "            preds, predsid = torch.max(output,1)\n",
        "            totalTest += b_y.size(0)\n",
        "            loss = loss_func(preds, b_y)   # cross entropy loss\n",
        "            loss.backward()                 # backpropagation, compute gradients\n",
        "            optimizer.step()                # apply gradients\n",
        "            running_loss += loss.item()\n",
        "            j+=1\n",
        "            correctTest += (predsid == b_y).sum().item()\n",
        "        totalcorrectTest[str(fold)].append(100 * correctTest // totalTest)\n",
        "        if(epoch % 10==0):\n",
        "            print(f'the loss on each epoch: {epoch}, loss: {running_loss/j}')\n",
        "            print(f'the test accuracy on each epoch: {epoch}, test accuracy: {100 * correctTest // totalTest}')\n",
        "        train_losses[str(fold)].append(running_loss / j)  # Append the running loss to the list for this fold\n",
        "\n",
        "    #total = total.to(\"cuda:0\")\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        cnn.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (b_x, b_y) in enumerate(test_loader):\n",
        "                b_x = Variable(b_x).type(torch.FloatTensor)\n",
        "                # calculate outputs by running the network\n",
        "                outputs = cnn(b_x)\n",
        "                # the class with the highest energy is what we choose as prediction\n",
        "                preds, predsid = torch.max(outputs,1)\n",
        "                total += b_y.size(0)\n",
        "                #predsid = predsid.to(\"cuda:0\")\n",
        "                predsid = predsid.to(\"cpu\")\n",
        "                correct += (predsid == b_y).sum().item()\n",
        "                all_labels[str(fold)].append(b_y.tolist())\n",
        "                all_probs[str(fold)].append(preds.tolist())\n",
        "        totalcorrect[str(fold)].append(100 * correct // total)\n",
        "        if(epoch % 10==0):\n",
        "            print(f'the validation accuracy on each epoch: {epoch}, validation accuracy: {100 * correct // total}')\n",
        "        if((100 * correctTest // totalTest) > 95):\n",
        "            break\n",
        "#print(f'Accuracy of the network on the 100 test : {100 * correct // total} %')\n",
        "print('Finished Training')\n",
        "\n",
        "# Letâ€™s quickly save our trained model:\n",
        "#!pwd\n",
        "#torch.save(cnn.state_dict(), \"./content\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVSipUZwos-Z"
      },
      "source": [
        "# make plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = plt.subplot(1, 1, 1)\n",
        "\n",
        "# Plotting the train losses on the first y-axis\n",
        "ax1.plot(train_losses['0'], color='black', label='Train Loss')\n",
        "ax1.set_xlabel(\"# of epoch\")\n",
        "ax1.set_ylabel(\"Training Loss\", color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "ax1.set_ylim(0, 1.00)\n",
        "\n",
        "# totalcorrectTest\n",
        "# Creating a second y-axis to plot the test correct values\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(totalcorrectTest['0'], color='blue', label='train Correct')\n",
        "ax2.plot(totalcorrect['0'], color='red', label='Test Correct')\n",
        "ax2.set_ylabel(\"Accuracy (%)\", color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "ax2.set_ylim(0, 100)\n",
        "ax2.axhline(y=50, color='green', linestyle='--', label='Threshold = 50')\n",
        "\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc='lower left')\n",
        "ax1.set_title(\"1st bacth\")\n",
        "#plt.legend(loc=\"center\")\n",
        "# Showing the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tiLQ1huietVJ",
        "outputId": "989e5fec-653c-487c-f628-1abf8441960b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make plot"
      ],
      "metadata": {
        "id": "x8zLrqHU63Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = plt.subplot(1, 1, 1)\n",
        "\n",
        "# Plotting the train losses on the first y-axis\n",
        "ax1.plot(train_losses['1'], color='black', label='Train Loss')\n",
        "ax1.set_xlabel(\"# of epoch\")\n",
        "ax1.set_ylabel(\"Training Loss\", color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "\n",
        "# Creating a second y-axis to plot the test correct values\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(totalcorrect['1'], color='red', label='Test Correct')\n",
        "ax2.set_ylabel(\"Test Accuracy (%)\", color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "ax2.axhline(y=50, color='green', linestyle='--', label='Threshold = 50')\n",
        "\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc='center')\n",
        "ax1.set_title(\"2nd bacth\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "id_ULsau66xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make 2nd plot"
      ],
      "metadata": {
        "id": "oqNRaISIeoDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve\n",
        "# Calculate ROC curve and AUC\n",
        "all_labelsID = np.concatenate([np.array(all_labels['0']).flatten(),\n",
        "                              np.array(all_labels['1']).flatten(),\n",
        "                              np.array(all_labels['2']).flatten(),\n",
        "                              np.array(all_labels['3']).flatten(),\n",
        "                              np.array(all_labels['4']).flatten(),\n",
        "                              np.array(all_labels['5']).flatten(),\n",
        "                              np.array(all_labels['6']).flatten(),\n",
        "                              np.array(all_labels['7']).flatten(),\n",
        "                              np.array(all_labels['8']).flatten(),\n",
        "                              np.array(all_labels['9']).flatten()])\n",
        "\n",
        "all_probsID = np.concatenate([np.array(all_probs['0']).flatten(),\n",
        "                              np.array(all_probs['1']).flatten(),\n",
        "                              np.array(all_probs['2']).flatten(),\n",
        "                              np.array(all_probs['3']).flatten(),\n",
        "                              np.array(all_probs['4']).flatten(),\n",
        "                              np.array(all_probs['5']).flatten(),\n",
        "                              np.array(all_probs['6']).flatten(),\n",
        "                              np.array(all_probs['7']).flatten(),\n",
        "                              np.array(all_probs['8']).flatten(),\n",
        "                              np.array(all_probs['9']).flatten()])\n",
        "fpr, tpr, thresholds = roc_curve(all_labelsID.tolist(), all_probsID.tolist())\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (1st batch)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X8xaZ9h7e2Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make 3rd plot"
      ],
      "metadata": {
        "id": "MuSAgKLP0UIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Precision-Recall curve and average precision\n",
        "precision, recall, _ = precision_recall_curve(all_labelsID.tolist(), all_probsID.tolist())\n",
        "average_precision = average_precision_score(all_labelsID.tolist(), all_probsID.tolist())\n",
        "plt.figure()\n",
        "plt.plot(precision, recall, color='darkorange', lw=2, label='PRC curve (area = %0.4f)' % average_precision)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iTzbatst0Uxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test the model"
      ],
      "metadata": {
        "id": "7oHnPKpxe6wY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjjcoqJLoqDC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "net = CNN() #0.001\n",
        "net.load_state_dict(torch.load(\"./content\"))\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for i, (b_x, b_y) in enumerate(test_loader):\n",
        "        b_x = Variable(b_x).type(torch.FloatTensor)\n",
        "        #print(b_x.shape)\n",
        "        #b_y = b_y.type(torch.LongTensor)\n",
        "        # calculate outputs by running the network\n",
        "        outputs = net(b_x)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        preds, predsid = torch.max(outputs,1)\n",
        "        total += b_y.size(0)\n",
        "        correct += (predsid == b_y).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test : {100 * correct // total} %')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlwL/+hKXP0ButWcAwUFWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}